---
layout:     post
title:      "客户端屏幕显示技术探索"
subtitle:   "Client，Screen，Display,技术总结"
date:       2018-03-31
author:     "Alla"
header-img: "img/post-bg-ios-uikit-uiviewcontroller.jpg"
tags:
- Enhance
- Client
- Principle
---
# iOS进阶系列 -- UI显示
图像想显示到屏幕上使人肉眼可见都需借助像素的力量。简单地说，每个像素由红，绿，蓝三种颜色组成，他们密集的排布在手机屏幕上，将任何图形通过不同的色值表现出来。
计算机显示的流程可以描述为将图像转化为一系列像素点的排列然后打印在屏幕上，由图像转化为像素点的过程又称为光栅化，就是从矢量的点线面的描述，变成像素的描述。
![](img/20180331/15216364897687.png)
回溯历史，可以从过去的 CRT 显示器原理说起。CRT 的电子枪按照上面方式，从上到下一行行扫描，扫描完成后显示器就呈现一帧画面，随后电子枪回到初始位置继续下一次扫描。为了把显示器的显示过程和系统的视频控制器进行同步，显示器（或者其他硬件）会用硬件时钟产生一系列的定时信号。当电子枪换到新的一行，准备进行扫描时，显示器会发出一个水平同步信号（horizonal synchronization），简称 HSync；而当一帧画面绘制完成后，电子枪回复到原位，准备画下一帧前，显示器会发出一个垂直同步信号（vertical synchronization），简称 VSync。显示器通常以固定频率进行刷新，这个刷新率就是 VSync 信号产生的频率。尽管现在的设备大都是液晶显示屏了，但原理仍然没有变。
##垂直同步与双缓冲技术
###CPU，GPU和Display协同工作流程
![](img/201803331/15216331834287.png)
1. CPU计算好图形的布局和纹理，通过总线，也就是主板交由GPU
2. GPU将资源进行绘制与渲染，渲染后的数据放置于帧缓冲区内
3. 同时，显示器经过视频控制器，从帧缓冲区内获取数据，进行显示
这样会有一个问题，帧缓冲区内数据填充和获取的整个过程会完全显示在显示器中，也就是大家看到的画面的闪烁。如何解决这个问题呢？下面就为大家介绍双缓冲和垂直同步技术。
####双缓冲
双缓冲技术将帧缓冲区设置为两个，即前端缓冲区（Front FrameBuffer）和后备缓冲区（Back FrameBuffer）。其中后备缓冲区负责图形的绘制，前端缓冲区负责屏幕的显示。当屏幕需要重绘时，只需将后备缓冲区的内容交换到前端缓冲区来，等待的时间只是内存拷贝的时间，不需要等待图形绘制的时间。因此，采用双缓冲技术，既可以解决屏幕闪烁的问题，又可以实现快速重绘。

但是双重缓冲有个问题，两个缓冲区随时都可能发生交换，所以就会出现这种情况：前缓冲区中的画面才刚传输了一半给显示器，两个缓冲区就发生交换了，后面传输的都是原来缓冲区中的画面，即下一帧画面。于是，显示器上的一幅画面成了前后两帧的结合，这就是画面撕裂。这种问题在高帧率情况下尤为显著，因为帧率越高，前后缓冲区的交换就约为频繁，发生这种画面没输出完就交换了的事件的概率自然也就更高。
![](img/201803331/15217207712068.png)
由上图可知

1.时间从0开始，进入第一个16ms：Display显示第0帧，CPU处理完第一帧后，GPU紧接其后处理继续第一帧。三者互不干扰，一切正常。 2.时间进入第二个16ms：因为早在上一个16ms时间内，第1帧已经由CPU，GPU处理完毕。故Display可以直接显示第1帧。显示没有问题。但在本16ms期间，CPU和GPU 却并未及时去绘制第2帧数据（注意前面的空白区），而是在本周期快结束时，CPU/GPU才去处理第2帧数据。 3.时间进入第3个16ms，此时Display应该显示第2帧数据，但由于CPU和GPU还没有处理完第2帧数据，故Display只能继续显示第一帧的数据，结果使得第1 帧多画了一次（对应时间段上标注了一个Jank）。 4.通过上述分析可知，此处发生Jank的关键问题在于，为何第1个16ms段内，CPU/GPU没有及时处理第2帧数据？原因很简单，CPU可能是在忙别的事情（比如某个应用通过sleep 固定时间来实现动画的逐帧显示），不知道该到处理UI绘制的时间了。可CPU一旦想起来要去处理第2帧数据，时间又错过了！

![](img/201803331/15217179701301.jpg)

那有什么办法能解决它呢？，那就是下面要讲的垂直同步技术
####垂直同步
垂直同步，英文简称为VSync，它其实是一种简写，完整的名字应该是“等待垂直同步信号”。
开启垂直同步，就相当于在帧缓冲区里架设了红绿灯，当显示器尚未完成一幅画面的刷新时，红灯亮起，两个缓冲区不允许交换；当显示器刷新完成一帧画面时，绿灯亮起，此时缓冲区可以进行交换了。这样以后就杜绝了“在进行数据传输的过程中交换缓冲区”的可能，自然也就解决了画面撕裂的问题。

不过为啥这个功能要叫“垂直同步”呢？这是因为在CRT显示器的年代，显示器的刷新是逐行或隔行刷新的，电子枪一行一行地打下去，打完每一行就称这一行完成了“水平同步”，打到最后一行的最有一个像素点就完成了一帧画面的显示，然后显示器会给显卡发送“垂直同步信号”，表明垂直向的像素点也完成了同步，即这一帧刷新完成了。
![](img/201803331/15217206826161.png)

由图可知，每收到VSYNC中断，CPU就开始处理各帧数据。整个过程非常完美。 不过，仔细琢磨图2却会发现一个新问题：图2中，CPU和GPU处理数据的速度似乎都能在16ms内完成，而且还有时间空余，也就是说，CPU/GPU的FPS（帧率，Frames Per Second）要高于Display的FPS。确实如此。由于CPU/GPU只在收到VSYNC时才开始数据处理，故它们的FPS被拉低到与Display的FPS相同。但这种处理并没有什么问题，因为Android设备的Display FPS一般是60，其对应的显示效果非常平滑。 如果CPU/GPU的FPS小于Display的FPS，会是什么情况呢？请看下图：

注意，垂直同步技术虽然能彻底杜绝画面撕裂，但是它的副作用同样明显--操作延迟。

在帧率比显示器刷新率高很多的情况下，为了将显示器的刷新时间和显卡向缓冲区写入画面的时间保持同步，必然就需要人为地增加延迟，来延后“过快生成的画面“向显示器的输出。因此在竞技游戏中，开启垂直同步后的手感会大打折扣。
![](img/201803331/15217207064460.png)

由图可知： 1.在第二个16ms时间段，Display本应显示B帧，但却因为GPU还在处理B帧，导致A帧被重复显示。 2.同理，在第二个16ms时间段内，CPU无所事事，因为A Buffer被Display在使用。B Buffer被GPU在使用。注意，一旦过了VSYNC时间点， CPU就不能被触发以处理绘制工作了。

为什么CPU不能在第二个16ms处开始绘制工作呢？原因就是只有两个Buffer。如果有第三个Buffer的存在，CPU就能直接使用它， 而不至于空闲。出于这一思路就引出了Triple Buffer。结果如图所示：

这里用一个实例来作说明：
![](img/201803331/15217186309787.jpg)

这是未开启垂直同步时，传统双重缓冲下的图像，由于 300fps 的高帧率，每两个“垂直同步信号“之间会生成高达 5 幅画面，这就导致了严重的画面撕裂。
![](img/201803331/15217186514904.jpg)

这是开启了垂直同步后的图像，可以看得出画面撕裂的问题确实得到了解决，但为了将帧缓存交换的时间和显示器刷新时间保持同步，帧缓存中的画面将会延后一个刷新周期被显示出来。在使用 60Hz 显示器时，一个刷新周期的时间高达 16.67ms，也就是说本来一秒五帧的图像延迟只有 3.3ms，现在因为要干等一个刷新周期，延迟一下子就增加到了 13.3ms，对于连 5ms 和 1ms 显示器都能分清的电竞选手而言，这多出来的10毫秒延迟是非常要命的。

- 哎呀，不开垂直同步会画面撕裂，开了又会有延迟，那画质和性能就不能兼得吗？
- 能啊，要想画质与操作兼得，有两个办法。
第一个办法，买个 G-SYNC 或 FreeSync 的电竞显示器
![](img/201803331/15217186972231.jpg)

这些显示器可以动态调整自己的刷新率，使其和显卡输出画面的帧率完全同步，这样不仅可以在解决画面撕裂的同时不出现操作延迟，还可以在帧率低于 60fps 的情况下同样提供垂直同步的效果，消除画面撕裂。不过，这毕竟是个要花大钱的办法，而且据我所知，几乎没有哪个电竞屏的屏幕素质是很优秀的，为了达到低延迟，许多电竞屏都采用了 TN 面板，对于电竞选手而言当然无可厚非，但对我这样的画面党来说，这样的屏幕看起来就有点难以接受了。

第二个办法，相信大家已经猜到了：三重缓冲！
##三重缓冲
![](img/201803331/15217187134665.jpg)

既然垂直同步的延迟是因为显卡输出完一幅图像就歇着等待红绿灯了，无法响应鼠标键盘最新的操作，那么我们为啥不让显卡一直工作呢？这样不就能一直响应最新的输入操作了吗？三重缓冲就是基于这种思路设计的，它在双重缓冲的基础上再加入了一个帧缓冲区，组成了一个前缓冲区，两个后缓冲区的规格。程序来回向两个后缓冲区写入图像，每次显示器刷新时，前缓冲区就和最近完成写入的那个后缓冲区交换。可以看到，即便有一个缓冲区要受到红绿灯的管控，另外两个缓冲区还是可以来回写入图像，于是就不需要人为增加画面延迟了。

![](img/201803331/15217207465381.png)

由图可知： 第二个16ms时间段，CPU使用C Buffer绘图。虽然还是会多显示A帧一次，但后续显示就比较顺畅了。 是不是Buffer越多越好呢？回答是否定的。由图4可知，在第二个时间段内，CPU绘制的第C帧数据要到第四个16ms才能显示， 这比双Buffer情况多了16ms延迟。所以，Buffer最好还是两个，三个足矣。

![](img/201803331/15217187292577.jpg)

这张图便说明了三重缓冲的原理，这种方法结合了前两种的优点。

不过三重缓冲也并非完美无瑕。首先由于需要一个额外的帧缓冲区，因此它会占用更多的显存空间。比如我们在 4K 分辨率下运行《质量效应：仙女座》，三重缓冲额外占用了约 200MB 的显存，对我们而言尚可接受。其次，它的延迟虽然远远低于双重缓冲下的垂直同步，但相比不开垂直同步还是可能略微高一点，因为无垂直同步的画面在给你带来撕裂的同时，也会包含最新帧的图像，如果开启了三重缓冲，那么画面中这“后面一帧“的多余元素就会被剔除，延迟自然会略微高于前者一点点。不过和满屏的画面撕裂相比，我显然还是会选择三重缓冲的……

看到这里，你肯定迫不及待地想要开启三重缓冲了吧，的确，垂直同步+三重缓冲是种非常棒的技术，可以有效地改善画面撕裂，同时不造成画面延迟。但是问题来了，DirectX 并不原生支持三重缓冲！而是使用了一种叫“预渲染队列“的方式。这种方式与三重缓冲不同的地方在于，它不会丢弃显卡渲染完却未被使用的帧（即过时的帧），而会强制将这些旧帧显示出来，因此会造成更大的操作延迟，甚至比光开垂直同步的延迟还要大。DirectX 的游戏若想使用三重缓冲，需要游戏厂商提供相应的支持。

很可惜的是，不少采用 DX API 游戏虽然在画面选项里提供了”三重缓冲“选项，实际上却是使用了“包含 3 个缓存空间的预渲染队列”，这些游戏使用的到底是不是真正的三重缓冲，只有你亲身体验后才能弄明白。所以，能不能开启三重缓冲，还要看游戏厂商的心情啊！

##屏幕显示的过程
![UI图形化](img/201803331/UI%E5%9B%BE%E5%BD%A2%E5%8C%96.png)
* 在 APP 内部的有4个阶段：
    1. 布局：在这个阶段，程序设置 View / Layer 的层级信息，设置 layer 的属性，如  frame，background color 等等。
    2. 创建 backing image：在这个阶段程序会创建 layer 的 backing image，无论是通过 setContents 将一个 image 传給 layer，还是通过 [drawRect:] 或 [drawLayer: inContext:] 来画出来的。所以 [drawRect:] 等函数是在这个阶段被调用的。
    3. 准备：在这个阶段，Core Animation 框架准备要渲染的 layer 的各种属性数据，以及要做的动画的参数，准备传递給 render server。同时在这个阶段也会解压要渲染的 image。（除了用 imageNamed：方法从 bundle 加载的 image 会立刻解压之外，其他的比如直接从硬盘读入，或者从网络上下载的 image 不会立刻解压，只有在真正要渲染的时候才会解压）。
    4. 提交：在这个阶段，Core Animation 打包 layer 的信息以及需要做的动画的参数，通过 IPC（inter-Process Communication）传递給 render server。
* 在 APP 外部的2个阶段：
当这些数据到达 render server 后，会被反序列化成 render tree。然后 render server 会做下面的两件事：
1. 根据 layer 的各种属性（如果是动画的，会计算动画 layer 的属性的中间值），用 OpenGL 准备渲染。
2. 渲染这些可视的 layer 到屏幕。
##离屏渲染
GPU屏幕渲染有两种方式
1>On-Screen Rendering:意为当前屏幕渲染

指GPU的渲染操作是在当前用于显示的屏幕缓冲区中进行

2>Off-Screen Rendering:离屏渲染

指GPU在当前屏幕缓冲区以外新开辟一个缓冲区进行渲染操作
.两种渲染方式比较

相比于当前屏幕渲染，离屏渲染的代价是很高的，主要体现在两个方面：

1>创建新缓冲区

要想进行离屏渲染，首先要创建一个新的缓冲区。

2>上下文切换

离屏渲染的整个过程，需要多次切换上下文环境：先是从当前屏幕（On-Screen）切换到离屏（Off-Screen）；等到离屏渲染结束以后，将离屏缓冲区的渲染结果显示到屏幕上有需要将上下文环境从离屏切换到当前屏幕。而上下文环境的切换是要付出很大代价的。

四.还有一种特殊的离屏渲染指:CPU渲染

如果重写了drawRect方法，并且使用任何Core Graphics的技术进行了绘制操作，就涉及到了CPU渲染。整个渲染过程由CPU在App内 同步地完成，渲染得到的bitmap最后再交由GPU用于显示。CoreGraphic通常是线程安全的，所以可以进行异步绘制，显示的时候再放回主线程，一个简单的异步绘制过程大致如下:
> - (void)display {
>    dispatch_async(backgroundQueue, ^{
>        CGContextRef ctx = CGBitmapContextCreate(...);
>        // draw in context...
>        CGImageRef img = CGBitmapContextCreateImage(ctx);
>        CFRelease(ctx);
>        dispatch_async(mainQueue, ^{
>            layer.contents = img;
>        });
>    });
> }

离屏渲染的触发方式

⭐️shadows（阴影）

⭐️shouldRasterize（光栅化）

⭐️masks（遮罩）

⭐️edge antialiasing（抗锯齿）

⭐️group opacity（不透明)

⭐️复杂形状设置圆角等…

⭐️渐变

⭐️UILabel, CATextLayer, Core Text……

为什么有时会使用离屏渲染

当使用圆角，阴影，遮罩的时候，图层属性的混合体被指定为在未预合成之前不能直接在屏幕中绘制，所以就需要屏幕外渲染被唤起。屏幕外渲染并不意味着软件绘制，但是它意味着图层必须在被显示之前在一个屏幕外上下文中被渲染（不论CPU还是GPU）.所以当使用离屏渲染的时候会很容易造成性能消耗，因为在OpenGL里离屏渲染会单独在内存中创建一个屏幕外缓冲区并进行渲染，而屏幕外缓冲区跟当前屏幕缓冲区上下文切换是很耗性能的。

七.Instruments工具检测

使用Instruments下的Core Animation有相关的检查选项

1>Color Offscreen-Rendered Yellow

开启后会把那些需要离屏渲染的图层高亮成黄色，这就意味着黄色图层可能存在性能问题。

2>Color Hits Green and Misses Red

如果shouldRasterize被设置成YES，对应的渲染结果会被缓存，如果图层是绿色，就表示这些缓存被复用；如果是红色就表示缓存会被重复创建，这就表示该处存在性能问题了。

八.该选择哪种实现方式?

1>尽量使用当前屏幕渲染

离屏渲染、CPU渲染可能带来的性能问题，一般情况下，我们要尽量使用当前屏幕渲染。

2>离屏渲染 和 CPU渲染

由于GPU的浮点运算能力比CPU强，CPU渲染的效率可能不如离屏渲染；但如果仅仅是实现一个简单的效果，直接使用CPU渲染的效率又可能比离屏渲染好，毕竟离屏渲染要涉及到缓冲区创建和上下文切换等耗时操作。

九.iOS系统版本区别

iOS 9.0 之前UIimageView跟UIButton设置圆角都会触发离屏渲染

iOS 9.0 之后UIButton设置圆角会触发离屏渲染，而UIImageView里png图片设置圆角不会触发离屏渲染了< iOS异步设置任意弧度高性能圆角图片>,如果设置其他阴影效果之类的还是会触发离屏渲染的。

##如何提升显示效率
GPU
相对于 CPU 来说，GPU 能干的事情比较单一：接收提交的纹理（Texture）和顶点描述（三角形），应用变换（transform）、混合并渲染，然后输出到屏幕上。通常你所能看到的内容，主要也就是纹理（图片）和形状（三角模拟的矢量图形）两类。
纹理的渲染
 所有的 Bitmap，包括图片、文本、栅格化的内容，最终都要由内存提交到显存，绑定为 GPU Texture。不论是提交到显存的过程，还是 GPU 调整和渲染 Texture 的过程，都要消耗不少 GPU 资源。当在较短时间显示大量图片时（比如 TableView 存在非常多的图片并且快速滑动时），CPU 占用率很低，GPU 占用非常高，界面仍然会掉帧。避免这种情况的方法只能是尽量减少在短时间内大量图片的显示，尽可能将多张图片合成为一张进行显示。当图片过大，超过 GPU 的最大纹理尺寸时，图片需要先由 CPU 进行预处理，这对 CPU 和 GPU 都会带来额外的资源消耗。目前来说，iPhone 4S 以上机型，纹理尺寸上限都是 4096x4096，更详细的资料可以看这里：iosres.com。所以，尽量不要让图片和视图的大小超过这个值。
视图的混合 (Composing)
 当多个视图（或者说 CALayer）重叠在一起显示时，GPU 会首先把他们混合到一起。如果视图结构过于复杂，混合的过程也会消耗很多 GPU 资源。为了减轻这种情况的 GPU 消耗，应用应当尽量减少视图数量和层次，并在不透明的视图里标明 opaque 属性以避免无用的 Alpha 通道合成。当然，这也可以用上面的方法，把多个视图预先渲染为一张图片来显示。
图形的生成。
 CALayer 的 border、圆角、阴影、遮罩（mask），CASharpLayer 的矢量图形显示，通常会触发离屏渲染（offscreen rendering），而离屏渲染通常发生在 GPU 中。当一个列表视图中出现大量圆角的 CALayer，并且快速滑动时，可以观察到 GPU 资源已经占满，而 CPU 资源消耗很少。这时界面仍然能正常滑动，但平均帧数会降到很低。为了避免这种情况，可以尝试开启 CALayer.shouldRasterize 属性，但这会把原本离屏渲染的操作转嫁到 CPU 上去。对于只需要圆角的某些场合，也可以用一张已经绘制好的圆角图片覆盖到原本视图上面来模拟相同的视觉效果。最彻底的解决办法，就是把需要显示的图形在后台线程绘制为图片，避免使用圆角、阴影、遮罩等属性。
2.哪些操作可能会过度消耗 CPU 或者 GPU，从而造成掉帧
视图上有太多的 layer 或者几何形状：
 如果视图的层级结构太复杂的话，当某些视图被渲染或者 frame 被修改的话，CPU 会花比较多得时间去重新计算 frame。尤其如果用 autolayout 的话，会更消耗 CPU。同时过多的几何结构会大大增多需要渲染的 OpenGL triangles 以及栅格化的操作（将 OpenGL 的 triangles 转化成像素）
太多的 overdraw：overdraw 是指一个像素点被多次地用颜色填充。这个主要是由于一些半透明的 layer 相互重叠造成的。GPU 的 fill-rate（用颜色填充像素的速率）是有限的。如果 overdraw 太多的话，势必会降低 GPU 的性能。
视图的延后载入：iOS 只有在展示 viewcontroller 的 view 或者访问 viewcontroller 的 view，比如说 someviewcontroller.view 的时候才会加载view。如果在用户点击了某个 button，并且在 button 的响应函数里做了很多消耗 cpu 的工作，这个时候如果 present 某个 viewcontroller 的话，会容易卡顿，尤其是如果viewcontroller 要从 database 里获取数据，或者从 nib 文件初始化 view 或者加载图片会更卡。
离屏的绘制：离屏的绘制有两种情况：1. 有些效果（如 rounded corners，layer masks，drop shadows 和 layer rasterization）不能直接的绘制到屏幕上，必须先绘制到一个 offscreen 的 image context 上，这种操作会引入额外的内存和 CPU 消耗。2. 实现了 drawRect 或者 drawLayer:inContext:，为了支持任意的绘制，core graphic 会创建一个大小跟要画的 view 一样的 backing image。并且当画完的以后要传输到 render server 上渲染。所以没事不要重载 drawRect 等函数却什么都不做。
图片解压：用 imageNamed：从 bundle 里加载会立马解压。一般的情况是在赋值给 UIImageView 的 image 或者 layer 的 contents 或者画到一个 core graphic context 里才会解压。
3.应该怎么做
1.离屏渲染
OpenGL 中，GPU 屏幕渲染有以下两种方式：
 * On-Screen Rendering 意为当前屏幕渲染，指的是 GPU 的渲染操作是在当前用于显示的屏幕缓冲区中进行。
Off-Screen Rendering 意为离屏渲染，指的是 GPU 在当前屏幕缓冲区以外新开辟一个缓冲区进行渲染操作。
相比于当前屏幕渲染，离屏渲染的代价是很高的，主要体现在两个方面：
创建新缓冲区 要想进行离屏渲染，首先要创建一个新的缓冲区。
上下文切换 离屏渲染的整个过程，需要多次切换上下文环境：先是从当前屏幕（On-Screen）切换到离屏（Off-Screen）；等到离屏渲染结束以后，将离屏缓冲区的渲染结果显示到屏幕上有需要将上下文环境从离屏切换到当前屏幕。而上下文环境的切换是要付出很大代价的。
所以在图形生成的步骤我们要尽可能的避免离屏渲染，或者开启 shouldRasterize 属性。
2.渲染优化的注意点
根据上面的描述，简单的汇总一些优化渲染的注意点：
隐藏的绘制：catextlayer 和 uilabel 都是将 text 画入 backing image 的。如果改了一个包含 text 的 view 的 frame 的话，text 会被重新绘制。
Rasterize：当使用 layer 的 shouldRasterize 的时候（记得设置适当的 layer 的 rasterizationScale），layer 会被强制绘制到一个 offscreen image 上，并且会被缓存起来。这种方法可以用来缓存绘制耗时（比如有比较绚的效果）但是不经常改的 layer，如果 layer 经常变，就不适合用。
离屏绘制： 使用 Rounded corner， layer masks， drop shadows 的效果可以使用 stretchable images。比如实现 rounded corner，可以将一个圆形的图片赋值于 layer 的 content 的属性。并且设置好 contentsCenter 和 contentScale 属性。
Blending and Overdraw ：如果一个 layer 被另一个 layer 完全遮盖，GPU 会做优化不渲染被遮盖的 layer，但是计算一个 layer 是否被另一个 layer 完全遮盖是很耗 cpu 的。将几个半透明的 layer 的 color 融合在一起也是很消耗的。
3.我们要做的：
设置 view 的 backgroundColor 为一个固定的，不透明的 color。 如果一个 view 是不透明的，设置 opaque 属性为 YES。（直接告诉程序这个是不透明的，而不是让程序去计算） 这样会减少 blending 和 overdraw。
如果使用 image 的话，尽量避免设置 image 的 alpha 为透明的，如果一些效果需要几个图片融合而成，就让设计用一张图画好，不要让程序在运行的时候去动态的融合。







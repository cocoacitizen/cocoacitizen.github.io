---
layout:     post
title:      "客户端屏幕显示技术探索"
subtitle:   "Client，Screen，Display,技术总结"
date:       2018-03-31
author:     "Alla"
header-img: "img/post-bg-ios-uikit-uiviewcontroller.jpg"
tags:
- Enhance
- Client
- Principle
---
# 图像显示漫谈
图形显示是用户与软件生产者交互的一个重要媒介，也是客户端工程师需要掌握的一个重要技术点。了解图形显示相关技术，对工程师进行相关性能优化以及架构师进行工程架构设计，打磨良好的产品体验，都有巨大的帮助。
##图像表示
我们周围的事物都是形状和颜色的。那么计算机如何来显示真实世界上的事物呢？
让我们先来了解几个概念吧。
###三原色
伟大的物理学家牛顿通过三棱镜把白色的光分解成七种不同颜色的光，实验发现，红，绿，蓝三种颜色的光是无法被分解的，所以我们就称红绿蓝为光的三原色。也就是说，我们可以通过不同比例的三种三原色来组合出各种各样的颜色。这也就是我们常说的RGB(A)模型。
###如何将颜色数字化
我们知道，计算机表示数据是用二进制0，1来表示的。现在计算机，一般使用32位（色深）来表示颜色，均分给三种三原色和透明度四个分量。这样能显示的颜色组合种类就是（2^8）^3 = 16777216种颜色了。
###纹理
纹理指GPU中的位图，存储在GPU的显存（video RAM）中。一方面它的格式是固定的，另外一方面GPU对纹理的大小有限制，比如长/宽必须是2的幂次方，最大不能超过2048或者4096等。那如果遇到纹理超过阀值的图片，比如说地图图片，又该如何处理呢？这就涉及到下面要讲的光栅化技术了。
###光栅化（Rasterize）
计算机显示的流程可以描述为将图像转化为一系列像素点的排列然后打印在屏幕上，由图像转化为像素点的过程又称为光栅化，就是从矢量的点线面的描述，变成像素的描述。光栅化的过程由GPU负责完成。
![](/img/20180331/15234303647983.jpg)
![](/img/20180331/15234303771461.jpg)
光栅化的本质其实就是坐标变换、几何离散化，然后再填充。
因为移动端GPU性能上的劣势以及对实时光栅化的极致要求，光栅化技术经历了立即渲染(Full-screen Raterization)到分区渲染(Tile-Based Raterization)，再到现在最先进的分区延迟渲染(Tile-Based Deferred Raterization)三个阶段。苹果的ARM处理器从A11开始，支持TBDR渲染。[参考链接](http://www.expreview.com/24705-3.html)

###像素与分辨率
从宏观到微观，一张位图图像，其实就是由一定数量的带有RGB颜色信息的点的矩阵构成的。这样的点就叫做**像素**（pixel）。而这个像素矩阵的大小就叫做图像的**分辨率**。
####Retina 显示技术
所谓的“Retina”其实是一种显示标准。是把更多的像素点压缩至一块屏幕里，从而达到更高的分辨率并提高屏幕显示的细腻程度。这种技术对硬件的配置要求会更高一些。
###手机屏幕的发展
根据材质的不同，手机屏幕可分为LCD（液晶显示器）与OLED（有机发光二极管）这两大类。其中LCD材质屏幕支持的显示技术又分为TFT，IPS和SLCD。该类屏幕具有广视角色彩还原度高的特点。OLED材质屏幕支持的显示技术分为AMOLED和Super AMOLED两种。其中AMOLED采用屏幕自发光的技术，但在阳光直射下很难看清楚，材质薄，寿命短，而后者被大量用在三星手机上，具有操作更领命，从任何角度都能看清楚屏幕的有点，但是对色彩的还原度差较差，色调艳丽不真实。[参考链接](http://www.elecfans.com/xianshi/20160223403202_a.html)
####Display P3技术
值得一提的是，苹果从iPhone7 产品开始，屏幕支持一种全新的显示技术叫Display P3,它可以表示更多数量的颜色，使屏幕对真实图像的还原度更真实

##协同工作流程
从UI工程师代码的编写到最后图像呈现在屏幕上，都经历了哪些工程，下面我们从硬件的角度来分析一下：
![graphic hardware workflo](/img/20180331/graphic%20hardware%20workflow.png)

1.CPU计算好图形的布局和纹理，通过总线，也就是主板交由GPU
2.GPU将资源进行绘制与渲染，渲染后的数据放置于帧缓冲区内
3.同时，显示器经过视频控制器，从帧缓冲区内获取数据，进行显示

从以上步骤，我们可总结出图像从生成到最终显示大概会经历计算-->绘制-->显示三个阶段。但是这样就会产生一个问题，帧缓冲区内数据填充和获取的整个过程会完全显示在显示器中，也就是大家看到的画面的闪烁。如何解决这个问题呢？下面就为大家介绍多重缓冲和垂直同步技术。
##多重缓冲和垂直同步
###双缓冲(Double Buffer)
双缓冲技术将帧缓冲区设置为两个，即前端缓冲区（Front FrameBuffer）和后备缓冲区（Back FrameBuffer）。其中后备缓冲区负责图形的绘制，前端缓冲区负责屏幕的显示。当屏幕需要重绘时，只需将后备缓冲区的内容交换到前端缓冲区来，等待的时间只是内存拷贝的时间，不需要等待图形绘制的时间。因此，采用双缓冲技术，既可以解决屏幕闪烁的问题，又可以实现快速重绘。如下图：
【双缓冲工作原理图】

但是双重缓冲有个问题，两个缓冲区随时都可能发生交换，所以就会出现这种情况：前缓冲区中的画面才刚传输了一半给显示器，两个缓冲区就发生交换了，后面传输的都是原来缓冲区中的画面，即下一帧画面。于是，显示器上的一幅画面成了前后两帧的结合，这就是画面撕裂。这种问题在高帧率情况下尤为显著，因为帧率越高，前后缓冲区的交换就约为频繁，发生这种画面没输出完就交换了的事件的概率自然也就更高，如下图：
![](/img/20180331/15217207712068.png)
由上图可知

1.时间从0开始，进入第一个16ms：Display显示第0帧，CPU处理完第一帧后，GPU紧接其后处理继续第一帧。三者互不干扰，一切正常。 
2.时间进入第二个16ms：因为早在上一个16ms时间内，第1帧已经由CPU，GPU处理完毕。故Display可以直接显示第1帧。显示没有问题。但在本16ms期间，CPU和GPU 却并未及时去绘制第2帧数据（注意前面的空白区），而是在本周期快结束时，CPU/GPU才去处理第2帧数据。 
3.时间进入第3个16ms，此时Display应该显示第2帧数据，但由于CPU和GPU还没有处理完第2帧数据，故Display只能继续显示第一帧的数据，结果使得第1 帧多画了一次（对应时间段上标注了一个Jank）。 
4.通过上述分析可知，此处发生Jank的关键问题在于，为何第1个16ms段内，CPU/GPU没有及时处理第2帧数据？原因很简单，CPU可能是在忙别的事情，不知道该到处理UI绘制的时间了。可CPU一旦想起来要去处理第2帧数据，时间又错过了！

![](/img/20180331/15234363022579.png)
那有什么办法能解决它呢？，那就是下面要讲的垂直同步技术
###垂直同步
在讲垂直同步技术之前，我们需要了解几个概念
####屏幕刷新率
屏幕刷新率指的是设备刷新屏幕的频率，单位为赫兹/Hz.
不同的显示器支持在不同分辨率下的不同刷新率。如下图，屏幕的刷新过程是每一行从左到右，也就是行刷新(水平刷新),从上到下，也就是屏幕刷新(垂直刷新)。当整个屏幕刷新完毕，即一个垂直刷新周期完成，会有短暂的空白期，此时发出VSync信号。
####帧率
帧率指的是Frame Rate，单位fps，即GPU生成帧的频率，越高越好。
####VSync
垂直同步，英文简称为VSync，它其实是一种简写，完整的名字应该是“等待垂直同步信号”。
开启垂直同步，就相当于在帧缓冲区里架设了红绿灯，当显示器尚未完成一幅画面的刷新时，红灯亮起，两个缓冲区不允许交换；当显示器刷新完成一帧画面时，绿灯亮起，此时缓冲区可以进行交换了。这样以后就杜绝了“在进行数据传输的过程中交换缓冲区”的可能，自然也就解决了画面撕裂的问题。
【垂直同步原理图】
![](/img/20180331/15217206826161.png)

由图可知，每收到VSYNC中断，CPU就开始处理各帧数据。整个过程非常完美。 

注意，垂直同步技术虽然能彻底杜绝画面撕裂，但是它的副作用同样明显--操作延迟。

在帧率比显示器刷新率高很多的情况下，为了将显示器的刷新时间和显卡向缓冲区写入画面的时间保持同步，必然就需要人为地增加延迟，来延后“过快生成的画面“向显示器的输出。因此在竞技游戏中，开启垂直同步后的手感会大打折扣。

不过，仔细琢磨图2却会发现一个新问题：图2中，CPU和GPU处理数据的速度似乎都能在16ms内完成，而且还有时间空余，也就是说，CPU/GPU的FPS（帧率，Frames Per Second）要高于Display的FPS。确实如此。由于CPU/GPU只在收到VSYNC时才开始数据处理，故它们的FPS被拉低到与Display的FPS相同。但这种处理并没有什么问题，因为移动端设备的Display FPS一般是60，其对应的显示效果非常平滑。 如果CPU/GPU的FPS小于Display的FPS，会是什么情况呢？请看下图：
![](/img/20180331/15217207064460.png)

由图可知： 
1.在第二个16ms时间段，Display本应显示B帧，但却因为GPU还在处理B帧，导致A帧被重复显示。 
2.同理，在第二个16ms时间段内，CPU无所事事，因为A Buffer被Display在使用。B Buffer被GPU在使用。注意，一旦过了VSYNC时间点， CPU就不能被触发以处理绘制工作了。

那么问题来了，不开垂直同步会画面撕裂，开了又会有延迟，那画质和性能就不能兼得吗？
其实是可以的，要想画质与操作兼得，有两个办法。
第一个办法，买个 G-SYNC 或 FreeSync 的电竞显示器
![](/img/20180331/15217186972231.jpg)

这些显示器可以动态调整自己的刷新率，使其和显卡输出画面的帧率完全同步，这样不仅可以在解决画面撕裂的同时不出现操作延迟，还可以在帧率低于 60fps 的情况下同样提供垂直同步的效果，消除画面撕裂。不过，这毕竟是个要花大钱的办法。
第二个办法就是要用到三重缓冲技术！
###三重缓冲(Triple Buffer)
![](/img/20180331/15217207465381.png)

由图可知： 第二个16ms时间段，CPU使用C Buffer绘图。虽然还是会多显示A帧一次，但后续显示就比较顺畅了。 是不是Buffer越多越好呢？回答是否定的。由图4可知，在第二个时间段内，CPU绘制的第C帧数据要到第四个16ms才能显示， 这比双Buffer情况多了16ms延迟。所以，Buffer最好还是两个，三个足矣。

现在一般的客户端屏幕都支持垂直同步技术，Android从4.1版本开始支持三重缓冲技术。iPhone目前支持双重缓冲技术。

##移动端显示（详细过程和特点）
如开篇所讲，图像从生成到最终显示大概会经历一下三个阶段，
* 计算：该阶段的工作由CPU来完成，主要包括数据的创建以及样式(style)和布局(layout)的计算
* 渲染：该阶段主要包含纹理的绘制（paint）和合成（composite）两部分工作
* 显示：这一部分和硬件结合的比较紧密，在这里就不赘述了。

![iOS Render Process](/img/20180331/iOS%20Render%20Process.png)

下面以iOS系统为例，
* 在APP内部有4个阶段：
    1. 布局：在这个阶段，程序设置 View / Layer 的层级信息，设置 layer 的属性。
    2. 创建 backing image：在这个阶段程序会创建 layer 的 backing image，无论是通过 setContents 将一个 image 传給 layer，还是通过 [drawRect:] 或 [drawLayer: inContext:] 来画出来的。所以 [drawRect:] 等函数是在这个阶段被调用的。
    3. 准备：在这个阶段，Core Animation 框架准备要渲染的 layer 的各种属性数据，以及要做的动画的参数，准备传递給 render server。同时在这个阶段也会解压要渲染的 image。（除了用 imageNamed：方法从 bundle 加载的 image 会立刻解压之外，其他的比如直接从硬盘读入，或者从网络上下载的 image 不会立刻解压，只有在真正要渲染的时候才会解压）。
    4. 提交：在这个阶段，Core Animation 打包 layer 的信息以及需要做的动画的参数，通过 IPC（inter-Process Communication）传递給 render server。
* 在APP外部有2个阶段：
当这些数据到达 render server 后，会被反序列化成 render tree。然后 render server 会做下面的两件事：
1. 根据 layer 的各种属性（如果是动画的，会计算动画 layer 的属性的中间值），用 OpenGL 准备渲染。
2. 渲染这些可视的 layer 到屏幕。

##影响显示性能的因素
从上面介绍的原理，我们不难看出，界面显示的过程主要是CPU和GPU协同工作的过程。所以CPU和GPU的负载均衡是影响界面显示性能的关键指标。下面分别阐述两者资源消耗的原因和常规的解决方案：
###CPU
* 现象：对象频繁的创建，调整和销毁
* 方案：
    * 不涉及UI操作的对象，尽量放到后台线程来创建其生命周期
    * 尽量推迟对象创建的时间，比如懒加载
    * 不经常变化的对象，请尽量复用或者缓存

* 现象：布局计算过于繁重复杂
* 方案：
    * 在后台线程提前计算好视图布局，比如：AsyncDisplayKit
    * 尽量不要频繁的调整视图布局，如果可以，请对其缓存

* 现象：大量大尺寸图片解码和图像绘制
* 方案：
    * 高质量图片解码以及图像绘制工作尽量放到非主线程
###GPU
* 现象：大量大尺寸图片展示
* 方案：
    * 尽量减少在短时间内大量图形的显示，尽可能将多张图形合成一张显示
    * 尽量少使用过大图片

* 现象：视图层级复杂
* 方案：
    * 尽量减少视图数量和层次
    * 及时将视图不透明信息告知系统

今天主要讲述了计算机图形学的基本知识，希望对客户端的同学有所帮助，谢谢！


<!--##离屏渲染
GPU屏幕渲染有两种方式
1>On-Screen Rendering:意为当前屏幕渲染

指GPU的渲染操作是在当前用于显示的屏幕缓冲区中进行

2>Off-Screen Rendering:离屏渲染

指GPU在当前屏幕缓冲区以外新开辟一个缓冲区进行渲染操作
.两种渲染方式比较

相比于当前屏幕渲染，离屏渲染的代价是很高的，主要体现在两个方面：

1>创建新缓冲区

要想进行离屏渲染，首先要创建一个新的缓冲区。

2>上下文切换

离屏渲染的整个过程，需要多次切换上下文环境：先是从当前屏幕（On-Screen）切换到离屏（Off-Screen）；等到离屏渲染结束以后，将离屏缓冲区的渲染结果显示到屏幕上有需要将上下文环境从离屏切换到当前屏幕。而上下文环境的切换是要付出很大代价的。

四.还有一种特殊的离屏渲染指:CPU渲染

如果重写了drawRect方法，并且使用任何Core Graphics的技术进行了绘制操作，就涉及到了CPU渲染。整个渲染过程由CPU在App内 同步地完成，渲染得到的bitmap最后再交由GPU用于显示。CoreGraphic通常是线程安全的，所以可以进行异步绘制，显示的时候再放回主线程，一个简单的异步绘制过程大致如下:
> - (void)display {
>    dispatch_async(backgroundQueue, ^{
>        CGContextRef ctx = CGBitmapContextCreate(...);
>        // draw in context...
>        CGImageRef img = CGBitmapContextCreateImage(ctx);
>        CFRelease(ctx);
>        dispatch_async(mainQueue, ^{
>            layer.contents = img;
>        });
>    });
> }

离屏渲染的触发方式

⭐️shadows（阴影）

⭐️shouldRasterize（光栅化）

⭐️masks（遮罩）

⭐️edge antialiasing（抗锯齿）

⭐️group opacity（不透明)

⭐️复杂形状设置圆角等…

⭐️渐变

⭐️UILabel, CATextLayer, Core Text……

为什么有时会使用离屏渲染

当使用圆角，阴影，遮罩的时候，图层属性的混合体被指定为在未预合成之前不能直接在屏幕中绘制，所以就需要屏幕外渲染被唤起。屏幕外渲染并不意味着软件绘制，但是它意味着图层必须在被显示之前在一个屏幕外上下文中被渲染（不论CPU还是GPU）.所以当使用离屏渲染的时候会很容易造成性能消耗，因为在OpenGL里离屏渲染会单独在内存中创建一个屏幕外缓冲区并进行渲染，而屏幕外缓冲区跟当前屏幕缓冲区上下文切换是很耗性能的。

七.Instruments工具检测

使用Instruments下的Core Animation有相关的检查选项

1>Color Offscreen-Rendered Yellow

开启后会把那些需要离屏渲染的图层高亮成黄色，这就意味着黄色图层可能存在性能问题。

2>Color Hits Green and Misses Red

如果shouldRasterize被设置成YES，对应的渲染结果会被缓存，如果图层是绿色，就表示这些缓存被复用；如果是红色就表示缓存会被重复创建，这就表示该处存在性能问题了。

八.该选择哪种实现方式?

1>尽量使用当前屏幕渲染

离屏渲染、CPU渲染可能带来的性能问题，一般情况下，我们要尽量使用当前屏幕渲染。

2>离屏渲染 和 CPU渲染

由于GPU的浮点运算能力比CPU强，CPU渲染的效率可能不如离屏渲染；但如果仅仅是实现一个简单的效果，直接使用CPU渲染的效率又可能比离屏渲染好，毕竟离屏渲染要涉及到缓冲区创建和上下文切换等耗时操作。

九.iOS系统版本区别

iOS 9.0 之前UIimageView跟UIButton设置圆角都会触发离屏渲染

iOS 9.0 之后UIButton设置圆角会触发离屏渲染，而UIImageView里png图片设置圆角不会触发离屏渲染了< iOS异步设置任意弧度高性能圆角图片>,如果设置其他阴影效果之类的还是会触发离屏渲染的。-->

/**##如何提升显示效率
GPU
相对于 CPU 来说，GPU 能干的事情比较单一：接收提交的纹理（Texture）和顶点描述（三角形），应用变换（transform）、混合并渲染，然后输出到屏幕上。通常你所能看到的内容，主要也就是纹理（图片）和形状（三角模拟的矢量图形）两类。
纹理的渲染
 所有的 Bitmap，包括图片、文本、栅格化的内容，最终都要由内存提交到显存，绑定为 GPU Texture。不论是提交到显存的过程，还是 GPU 调整和渲染 Texture 的过程，都要消耗不少 GPU 资源。当在较短时间显示大量图片时（比如 TableView 存在非常多的图片并且快速滑动时），CPU 占用率很低，GPU 占用非常高，界面仍然会掉帧。避免这种情况的方法只能是尽量减少在短时间内大量图片的显示，尽可能将多张图片合成为一张进行显示。当图片过大，超过 GPU 的最大纹理尺寸时，图片需要先由 CPU 进行预处理，这对 CPU 和 GPU 都会带来额外的资源消耗。目前来说，iPhone 4S 以上机型，纹理尺寸上限都是 4096x4096，更详细的资料可以看这里：iosres.com。所以，尽量不要让图片和视图的大小超过这个值。
视图的混合 (Composing)
 当多个视图（或者说 CALayer）重叠在一起显示时，GPU 会首先把他们混合到一起。如果视图结构过于复杂，混合的过程也会消耗很多 GPU 资源。为了减轻这种情况的 GPU 消耗，应用应当尽量减少视图数量和层次，并在不透明的视图里标明 opaque 属性以避免无用的 Alpha 通道合成。当然，这也可以用上面的方法，把多个视图预先渲染为一张图片来显示。
图形的生成。
 CALayer 的 border、圆角、阴影、遮罩（mask），CASharpLayer 的矢量图形显示，通常会触发离屏渲染（offscreen rendering），而离屏渲染通常发生在 GPU 中。当一个列表视图中出现大量圆角的 CALayer，并且快速滑动时，可以观察到 GPU 资源已经占满，而 CPU 资源消耗很少。这时界面仍然能正常滑动，但平均帧数会降到很低。为了避免这种情况，可以尝试开启 CALayer.shouldRasterize 属性，但这会把原本离屏渲染的操作转嫁到 CPU 上去。对于只需要圆角的某些场合，也可以用一张已经绘制好的圆角图片覆盖到原本视图上面来模拟相同的视觉效果。最彻底的解决办法，就是把需要显示的图形在后台线程绘制为图片，避免使用圆角、阴影、遮罩等属性。
2.哪些操作可能会过度消耗 CPU 或者 GPU，从而造成掉帧
视图上有太多的 layer 或者几何形状：
 如果视图的层级结构太复杂的话，当某些视图被渲染或者 frame 被修改的话，CPU 会花比较多得时间去重新计算 frame。尤其如果用 autolayout 的话，会更消耗 CPU。同时过多的几何结构会大大增多需要渲染的 OpenGL triangles 以及栅格化的操作（将 OpenGL 的 triangles 转化成像素）
太多的 overdraw：overdraw 是指一个像素点被多次地用颜色填充。这个主要是由于一些半透明的 layer 相互重叠造成的。GPU 的 fill-rate（用颜色填充像素的速率）是有限的。如果 overdraw 太多的话，势必会降低 GPU 的性能。
视图的延后载入：iOS 只有在展示 viewcontroller 的 view 或者访问 viewcontroller 的 view，比如说 someviewcontroller.view 的时候才会加载view。如果在用户点击了某个 button，并且在 button 的响应函数里做了很多消耗 cpu 的工作，这个时候如果 present 某个 viewcontroller 的话，会容易卡顿，尤其是如果viewcontroller 要从 database 里获取数据，或者从 nib 文件初始化 view 或者加载图片会更卡。
离屏的绘制：离屏的绘制有两种情况：1. 有些效果（如 rounded corners，layer masks，drop shadows 和 layer rasterization）不能直接的绘制到屏幕上，必须先绘制到一个 offscreen 的 image context 上，这种操作会引入额外的内存和 CPU 消耗。2. 实现了 drawRect 或者 drawLayer:inContext:，为了支持任意的绘制，core graphic 会创建一个大小跟要画的 view 一样的 backing image。并且当画完的以后要传输到 render server 上渲染。所以没事不要重载 drawRect 等函数却什么都不做。
图片解压：用 imageNamed：从 bundle 里加载会立马解压。一般的情况是在赋值给 UIImageView 的 image 或者 layer 的 contents 或者画到一个 core graphic context 里才会解压。
3.应该怎么做
1.离屏渲染
OpenGL 中，GPU 屏幕渲染有以下两种方式：
 * On-Screen Rendering 意为当前屏幕渲染，指的是 GPU 的渲染操作是在当前用于显示的屏幕缓冲区中进行。
Off-Screen Rendering 意为离屏渲染，指的是 GPU 在当前屏幕缓冲区以外新开辟一个缓冲区进行渲染操作。
相比于当前屏幕渲染，离屏渲染的代价是很高的，主要体现在两个方面：
创建新缓冲区 要想进行离屏渲染，首先要创建一个新的缓冲区。
上下文切换 离屏渲染的整个过程，需要多次切换上下文环境：先是从当前屏幕（On-Screen）切换到离屏（Off-Screen）；等到离屏渲染结束以后，将离屏缓冲区的渲染结果显示到屏幕上有需要将上下文环境从离屏切换到当前屏幕。而上下文环境的切换是要付出很大代价的。
所以在图形生成的步骤我们要尽可能的避免离屏渲染，或者开启 shouldRasterize 属性。
2.渲染优化的注意点
根据上面的描述，简单的汇总一些优化渲染的注意点：
隐藏的绘制：catextlayer 和 uilabel 都是将 text 画入 backing image 的。如果改了一个包含 text 的 view 的 frame 的话，text 会被重新绘制。
Rasterize：当使用 layer 的 shouldRasterize 的时候（记得设置适当的 layer 的 rasterizationScale），layer 会被强制绘制到一个 offscreen image 上，并且会被缓存起来。这种方法可以用来缓存绘制耗时（比如有比较绚的效果）但是不经常改的 layer，如果 layer 经常变，就不适合用。
离屏绘制： 使用 Rounded corner， layer masks， drop shadows 的效果可以使用 stretchable images。比如实现 rounded corner，可以将一个圆形的图片赋值于 layer 的 content 的属性。并且设置好 contentsCenter 和 contentScale 属性。
Blending and Overdraw ：如果一个 layer 被另一个 layer 完全遮盖，GPU 会做优化不渲染被遮盖的 layer，但是计算一个 layer 是否被另一个 layer 完全遮盖是很耗 cpu 的。将几个半透明的 layer 的 color 融合在一起也是很消耗的。
3.我们要做的：
设置 view 的 backgroundColor 为一个固定的，不透明的 color。 如果一个 view 是不透明的，设置 opaque 属性为 YES。（直接告诉程序这个是不透明的，而不是让程序去计算） 这样会减少 blending 和 overdraw。
如果使用 image 的话，尽量避免设置 image 的 alpha 为透明的，如果一些效果需要几个图片融合而成，就让设计用一张图画好，不要让程序在运行的时候去动态的融合。**/






